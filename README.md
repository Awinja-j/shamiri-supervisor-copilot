# Shamiri Supervisor Copilot

A web-based AI-powered dashboard that amplifies a Supervisor's capacity to review therapy sessions conducted by Shamiri Fellows.

![Dashboard Preview](public/dashboard-preview.png)

## ğŸŒ Live Demo

**Production URL**: [shamiri-supervisor-copilot.vercel.app](https://shamiri-supervisor-copilot.vercel.app)

**Demo Credentials**:
- Email: `kamau@shamiri.org`
- Password: `demo123`

---

## ğŸ¯ What This Solves

At Shamiri, Fellows (18-22 year old lay providers) deliver group therapy sessions to young people across Kenya. Supervisors are responsible for reviewing these sessions to ensure quality and safety - but they cannot listen to every single 1-hour recording.

The Shamiri Supervisor Copilot uses Generative AI to:
- Automatically analyze session transcripts
- Score Fellows on 3 quality metrics
- Flag sessions with safety concerns (self-harm, crisis)
- Allow Supervisors to validate or override AI findings

This transforms a Supervisor's capacity from reviewing **5 sessions/week** to **50+ sessions/week**.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Next.js 15 (App Router) | React framework with server components |
| **Language** | TypeScript | Type safety across the entire codebase |
| **Styling** | Tailwind CSS | Utility-first responsive styling |
| **Database** | PostgreSQL (Neon) | Serverless Postgres for sessions, fellows, analyses |
| **ORM** | Prisma | Type-safe database queries with migrations |
| **AI** | OpenAI GPT-4o | Session transcript analysis |
| **Validation** | Zod | Structured AI output validation |
| **Deployment** | Vercel | Serverless hosting with edge network |

---

## âš™ï¸ Setup & Installation

### Prerequisites

Before you begin, ensure you have:
- Node.js 18+ installed
- A [Neon](https://neon.tech) account (free tier works)
- An [OpenAI](https://platform.openai.com) API key

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/shamiri-supervisor-copilot.git
cd shamiri-supervisor-copilot
```

### 2. Install Dependencies
```bash
npm install
```

### 3. Set Up Environment Variables

Create a `.env` file in the root directory:
```env
# Database (Neon PostgreSQL)
DATABASE_URL="postgresql://username:password@ep-xxx.neon.tech/dbname?sslmode=require"

# AI
OPENAI_API_KEY="sk-proj-your-key-here"

# Auth
NEXTAUTH_SECRET="your-random-secret-string"
NEXTAUTH_URL="http://localhost:3000"
```

#### Getting Your Credentials:

**Neon Database URL:**
1. Go to [console.neon.tech](https://console.neon.tech)
2. Create a new project
3. Copy the **Connection String** from the dashboard
4. Paste it as `DATABASE_URL`

**OpenAI API Key:**
1. Go to [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Click **Create new secret key**
3. Copy and paste as `OPENAI_API_KEY`

**NextAuth Secret:**
```bash
# Generate a random secret
openssl rand -base64 32
```

### 4. Set Up the Database
```bash
# Generate Prisma Client
npx prisma generate

# Run database migrations
npx prisma migrate deploy

# Seed with sample data
npm run seed
```

### 5. Start the Development Server
```bash
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000)

Login with:
- **Email**: kamau@shamiri.org
- **Password**: demo123

---

## ğŸ—„ï¸ Database Schema
```
Supervisor
    â”‚
    â””â”€â”€ Fellow (many)
            â”‚
            â””â”€â”€ Session (many)
                    â”‚
                    â”œâ”€â”€ AIAnalysis (many - tracks history)
                    â”œâ”€â”€ RiskFlag (many)
                    â””â”€â”€ SupervisorOverride (many)
```

### Models:

**Supervisor** - The person using this dashboard
```
id, name, email, createdAt
```

**Fellow** - The lay provider conducting sessions
```
id, name, cohort, supervisorId
```

**Session** - A recorded therapy session
```
id, fellowId, groupId, sessionDate, transcript, durationMinutes, status
```

**AIAnalysis** - Structured AI output for a session
```
id, sessionId, modelVersion
contentScore, contentEvidence, contentReasoning
facilitationScore, facilitationEvidence, facilitationReasoning
protocolScore, protocolEvidence, protocolReasoning
riskFlag, riskSeverity, riskConfidence, riskQuotes
```

**SupervisorOverride** - Human-in-the-loop decisions
```
id, analysisId, supervisorId, action, previousFlag, newFlag, notes
```

---

## ğŸ¤– AI Analysis Engine

### How It Works

When a Supervisor clicks "Run AI Analysis" on a session:
```
1. Transcript sent to GPT-4o with structured prompt
        â†“
2. AI evaluates 3 quality metrics (scored 1-3)
        â†“
3. AI performs risk assessment (SAFE or RISK)
        â†“
4. Output validated against Zod schema
        â†“
5. Result saved to PostgreSQL
        â†“
6. UI updates with scores, evidence, and risk flags
```

### Quality Metrics

**Metric 1: Content Coverage** - Did the Fellow teach Growth Mindset?
- `3 (Complete)`: Explained concept, gave examples, checked understanding
- `2 (Partial)`: Mentioned concept but didn't engage deeply
- `1 (Missed)`: Failed to cover Growth Mindset

**Metric 2: Facilitation Quality** - How did they deliver it?
- `3 (Excellent)`: Warm, empathetic, open questions, validated feelings
- `2 (Adequate)`: Polite but transactional, minimal engagement
- `1 (Poor)`: Dominated conversation, interrupted students

**Metric 3: Protocol Safety** - Did they stay within boundaries?
- `3 (Adherent)`: Stayed on curriculum, handled distractions well
- `2 (Minor Drift)`: Got distracted but returned to topic
- `1 (Violation)`: Gave unauthorized medical/relationship advice

### Risk Detection

The AI flags sessions as `RISK` **only** when there is explicit mention of:
- Self-harm with plan or intent
- Suicide with specificity
- Abuse currently happening

This high threshold is intentional - false positives desensitize supervisors.

---

## ğŸ”„ Human-in-the-Loop

AI is imperfect. Every AI finding can be overridden by a Supervisor:

1. Supervisor reviews AI assessment
2. Clicks **"Review & Override"**
3. Writes reasoning in notes field
4. Selects new status (Safe / Risk)
5. Override saved to `SupervisorOverride` table with full audit trail

This creates accountability and improves trust in the system.

---

## ğŸš€ Scaling Strategy: Serving 10 Million Youths

> *"As we scale to serve 10 million youths, our Supervisors are facing a quality assurance bottleneck."*

This is not just a technical challenge - it's a mission-critical requirement. Here's how this architecture scales:

### Current Implementation

The current system is designed for **early-scale deployment** (~1,000 active users):

| Component | Current Implementation | Capacity |
|-----------|----------------------|----------|
| **Hosting** | Vercel Serverless | Auto-scales to thousands |
| **Database** | Neon Serverless Postgres | 500MB, ~10K sessions |
| **AI Analysis** | Synchronous OpenAI calls | ~30s per analysis |
| **Caching** | None (direct DB queries) | Sufficient for demo |
| **Auth** | Simple credential check | 1 supervisor |

### Bottlenecks at 10M Users

As Shamiri scales, three bottlenecks will emerge:
```
1. AI COST EXPLOSION
   10M sessions Ã— $0.03/analysis = $300,000/month
   
2. DATABASE OVERLOAD  
   10K supervisors Ã— 50 queries/hour = 500K queries/hour
   
3. AI LATENCY
   30 second analysis blocks supervisor workflow
```

### Future Architecture for 10M Users
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           VERCEL EDGE NETWORK                   â”‚
â”‚     (175+ global locations, Kenya included)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NEXT.JS APP LAYER                  â”‚
â”‚  â€¢ Server Components (zero client JS overhead) â”‚
â”‚  â€¢ Edge Functions (runs close to Nairobi)      â”‚
â”‚  â€¢ Optimistic UI updates                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    REDIS     â”‚  â”‚  POSTGRES  â”‚  â”‚  JOB QUEUE  â”‚
â”‚  (Upstash)   â”‚  â”‚   (Neon)   â”‚  â”‚  (Inngest)  â”‚
â”‚              â”‚  â”‚            â”‚  â”‚             â”‚
â”‚ â€¢ Session    â”‚  â”‚ â€¢ All data â”‚  â”‚ â€¢ AI jobs   â”‚
â”‚   list cache â”‚  â”‚ â€¢ Indexes  â”‚  â”‚ â€¢ Retries   â”‚
â”‚ â€¢ Analysis   â”‚  â”‚ â€¢ Pooling  â”‚  â”‚ â€¢ Batch     â”‚
â”‚   cache(24h) â”‚  â”‚            â”‚  â”‚   analysis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   OPENAI API    â”‚
                               â”‚ â€¢ GPT-4o-mini   â”‚
                               â”‚   (cost saving) â”‚
                               â”‚ â€¢ Batch API     â”‚
                               â”‚   (50% cheaper) â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Specific Improvements Roadmap

#### Phase 1: 10K Users (Next 6 months)
```markdown
- [ ] Redis caching (Upstash)
      WHY: Reduce database load by 80%
      IMPACT: Dashboard loads in <100ms instead of 500ms
      
- [ ] Background job queue (Inngest)
      WHY: AI analysis takes 30s - don't block the UI
      IMPACT: Supervisor gets instant "queued" response
      
- [ ] Database connection pooling (PgBouncer)
      WHY: Neon has connection limits
      IMPACT: Handle 1,000 concurrent supervisors
```

#### Phase 2: 100K Users (6-12 months)
```markdown
- [ ] Switch to GPT-4o-mini for standard sessions
      WHY: 10x cheaper than GPT-4o, 90% as accurate
      IMPACT: Cost drops from $300K to $30K/month
      
- [ ] Batch API for bulk analysis
      WHY: OpenAI Batch API is 50% cheaper
      IMPACT: Analyze 1,000 sessions overnight at half cost
      
- [ ] Read replicas for database
      WHY: Separate read/write traffic
      IMPACT: Dashboard queries don't compete with writes
```

#### Phase 3: 1M+ Users (12-24 months)
```markdown
- [ ] Fine-tuned model on Shamiri data
      WHY: Custom model trained on real session data
      IMPACT: 10x cheaper, more accurate, culturally aware
      
- [ ] Multilingual support (Swahili, Kikuyu, Luo)
      WHY: Kenya is multilingual, sessions include code-switching
      IMPACT: More accurate analysis of real transcripts
      
- [ ] Offline-first mobile app
      WHY: Rural Kenya has unreliable internet
      IMPACT: Fellows can record sessions offline, sync later
      
- [ ] Real-time audio transcription
      WHY: Manual transcript creation is a bottleneck
      IMPACT: Automatic transcription eliminates data entry
```

### Cost Projection at Scale

| Scale | Sessions/Month | Without Optimization | With Optimization |
|-------|---------------|---------------------|-------------------|
| 1K users | 10,000 | $300 | $30 |
| 10K users | 100,000 | $3,000 | $150 |
| 100K users | 1,000,000 | $30,000 | $600 |
| 1M users | 10,000,000 | $300,000 | $3,000 |

*Optimization includes: caching (80% hit rate) + GPT-4o-mini (90% of sessions) + Batch API*

### African Context Considerations

Scaling for Shamiri is not just about technology - it's about context:
```markdown
- LOW BANDWIDTH: UI optimized for 2G/3G connections
  Current: Minimal JS bundle, no heavy images
  Future: Progressive loading, offline support

- CODE SWITCHING: Kenyan sessions mix English + Swahili
  Current: AI prompt acknowledges African context
  Future: Fine-tuned model trained on Kenyan speech patterns

- MOBILE FIRST: Supervisors use smartphones, not laptops
  Current: Responsive Tailwind CSS
  Future: Dedicated mobile app (React Native)

- POWER RELIABILITY: Intermittent electricity in rural areas
  Current: Auto-save analysis results
  Future: Offline-capable PWA with background sync
```

---

## ğŸ¤ AI Collaboration Report

As required by the assignment, here is a transparent breakdown of AI usage:

### Code Generated with AI Assistance (~60%)

| Component | AI Tool Used | What Was Generated |
|-----------|-------------|-------------------|
| Prisma schema | Claude | Initial model design |
| API routes | Cursor/Copilot | Boilerplate structure |
| Tailwind UI | Claude | Component styling |
| Zod schemas | Claude | Validation schemas |
| Seed data | Claude | Synthetic transcripts |

### Hand-Written Code (~40%)

| Component | Why Hand-Written |
|-----------|----------------|
| AI prompt engineering | Business logic - must understand deeply |
| Risk detection thresholds | Safety-critical - cannot delegate |
| Database query optimization | Performance - requires domain knowledge |
| Auth flow | Security-critical - requires careful review |
| Scaling architecture | Architecture decisions require expertise |

### Verification Process

Every AI-generated piece of code was verified by:

1. **TypeScript strict mode** - All code passes type checking
2. **Manual review** - Read every line before accepting
3. **Testing** - Ran locally and verified output
4. **Security check** - Reviewed for injection, auth bypass risks
5. **Logic validation** - Verified business logic matches requirements

### Key Learning

> *"I used AI to move fast on boilerplate, but hand-coded all business logic. This ensures I deeply understand every system decision and can defend them in a technical interview."*

---

## ğŸ“ Project Structure
```
shamiri-supervisor-copilot/
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma          # Database models
â”‚   â””â”€â”€ migrations/            # SQL migration history
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ seed.ts                # Database seeding script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ login/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ route.ts
â”‚   â”‚   â”‚   â””â”€â”€ sessions/
â”‚   â”‚   â”‚       â”œâ”€â”€ route.ts          # GET all sessions
â”‚   â”‚   â”‚       â””â”€â”€ [id]/
â”‚   â”‚   â”‚           â”œâ”€â”€ route.ts      # GET single session
â”‚   â”‚   â”‚           â””â”€â”€ analyze/
â”‚   â”‚   â”‚               â””â”€â”€ route.ts  # POST trigger analysis
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx       # Main supervisor dashboard
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx       # Login page
â”‚   â”‚   â”œâ”€â”€ session/
â”‚   â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx   # Session detail + AI analysis
â”‚   â”‚   â””â”€â”€ page.tsx           # Root redirect
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ ai-service.ts      # OpenAI integration
â”‚       â”œâ”€â”€ analysis-schema.ts # Zod validation schemas
â”‚       â”œâ”€â”€ auth.ts            # Authentication logic
â”‚       â”œâ”€â”€ mock-data.ts       # Development mock data
â”‚       â””â”€â”€ prisma.ts          # Database client
â”œâ”€â”€ .env                       # Environment variables (not committed)
â”œâ”€â”€ vercel.json                # Vercel deployment config
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”’ Environment Variables Reference

| Variable | Required | Description |
|----------|----------|-------------|
| `DATABASE_URL` | âœ… Yes | Neon PostgreSQL connection string |
| `OPENAI_API_KEY` | âœ… Yes | OpenAI API key for analysis |
| `NEXTAUTH_SECRET` | âœ… Yes | Random string for session encryption |
| `NEXTAUTH_URL` | âœ… Yes | Your deployment URL |

---

## License

